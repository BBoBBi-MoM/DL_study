{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchsummary import summary\n",
    "\n",
    "from PIL import Image"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# ResNet (2015)\n",
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "##### Basic Block\n",
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://production-media.paperswithcode.com/methods/resnet-e1548261477164_2_mD02h5A.png\" width=\"500\" height=\"250\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride=1 ,downsampling = False):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False )\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=1, stride=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        if downsampling:\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(out_channels)\n",
    "                )\n",
    "        else:\n",
    "            downsample = None\n",
    "        self.downsample = downsample\n",
    "\n",
    "    def forward(self,x):\n",
    "        i = x\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            i = self.downsample(i)\n",
    "\n",
    "        x+=i\n",
    "        x = self.relu(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "##### Bottleneck\n",
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcTWVMFtZ_ob861NdYsCf2ddOCqxFXdC4WDeFQ&usqp=CAU\" width=\"500\" height=\"300\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Bottleneck(nn.Module):\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self,in_channels,out_channels,stride=1,downsampling=False):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "        self.conv3 = nn.Conv2d(out_channels, out_channels*self.expansion, kernel_size=1, stride=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(out_channels*self.expansion)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        if downsampling:\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, self.expansion*out_channels, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(self.expansion*out_channels)\n",
    "            )\n",
    "        else:\n",
    "            downsample =None\n",
    "        self.downsample = downsample\n",
    "\n",
    "    def forward(self,x):\n",
    "        i = x\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.bn3(x)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            i = self.downsample(i)\n",
    "\n",
    "        x += i\n",
    "        x = self.relu(x)\n",
    "        return x"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### ResNet18\n",
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://blog.kakaocdn.net/dn/Bl6lG/btrDyFKASgY/LD9Z8BvHg1S76DcRe7yJd0/img.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet18(nn.Module):\n",
    "    def __init__(self,classes):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.conv_layer1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=3, out_channels=64, kernel_size=7, stride=2, padding=3 ,bias=False),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU()\n",
    "            )\n",
    "        \n",
    "        self.pooling_layer = nn.MaxPool2d(kernel_size=3, stride=2,padding=1)\n",
    "\n",
    "        self.basic_block1 = nn.Sequential(\n",
    "            BasicBlock(in_channels=64,out_channels=64,stride=1,downsampling=False),\n",
    "            BasicBlock(in_channels=64,out_channels=64,stride=1,downsampling=False)\n",
    "            )\n",
    "        \n",
    "        self.basic_block2 = nn.Sequential(\n",
    "            BasicBlock(in_channels=64,out_channels=128,stride=2,downsampling=True),\n",
    "            BasicBlock(in_channels=128,out_channels=128,stride=1,downsampling=False)\n",
    "        )\n",
    "\n",
    "        self.basic_block3 = nn.Sequential(\n",
    "            BasicBlock(in_channels=128,out_channels=256,stride=2,downsampling=True),\n",
    "            BasicBlock(in_channels=256,out_channels=256,stride=1,downsampling=False)\n",
    "        )\n",
    "\n",
    "        self.basic_block4 = nn.Sequential(\n",
    "            BasicBlock(in_channels=256,out_channels=512,stride=2,downsampling=True),\n",
    "            BasicBlock(in_channels=512,out_channels=512,stride=1,downsampling=False)\n",
    "        )\n",
    "\n",
    "        self.avg_pooling_layer = nn.AdaptiveAvgPool2d(output_size=(1,1))\n",
    "        self.output_layer = nn.Linear(512,classes)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        x = self.conv_layer1(x)\n",
    "        x = self.pooling_layer(x)\n",
    "        x = self.basic_block1(x)\n",
    "        x = self.basic_block2(x)\n",
    "        x = self.basic_block3(x)\n",
    "        x = self.basic_block4(x)\n",
    "        x = self.avg_pooling_layer(x)\n",
    "        x = x.view(x.shape[0],-1)\n",
    "        x = self.output_layer(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 64, 112, 112]           9,408\n",
      "       BatchNorm2d-2         [-1, 64, 112, 112]             128\n",
      "              ReLU-3         [-1, 64, 112, 112]               0\n",
      "         MaxPool2d-4           [-1, 64, 56, 56]               0\n",
      "            Conv2d-5           [-1, 64, 56, 56]          36,864\n",
      "       BatchNorm2d-6           [-1, 64, 56, 56]             128\n",
      "              ReLU-7           [-1, 64, 56, 56]               0\n",
      "            Conv2d-8           [-1, 64, 56, 56]           4,096\n",
      "       BatchNorm2d-9           [-1, 64, 56, 56]             128\n",
      "             ReLU-10           [-1, 64, 56, 56]               0\n",
      "       BasicBlock-11           [-1, 64, 56, 56]               0\n",
      "           Conv2d-12           [-1, 64, 56, 56]          36,864\n",
      "      BatchNorm2d-13           [-1, 64, 56, 56]             128\n",
      "             ReLU-14           [-1, 64, 56, 56]               0\n",
      "           Conv2d-15           [-1, 64, 56, 56]           4,096\n",
      "      BatchNorm2d-16           [-1, 64, 56, 56]             128\n",
      "             ReLU-17           [-1, 64, 56, 56]               0\n",
      "       BasicBlock-18           [-1, 64, 56, 56]               0\n",
      "           Conv2d-19          [-1, 128, 28, 28]          73,728\n",
      "      BatchNorm2d-20          [-1, 128, 28, 28]             256\n",
      "             ReLU-21          [-1, 128, 28, 28]               0\n",
      "           Conv2d-22          [-1, 128, 28, 28]          16,384\n",
      "      BatchNorm2d-23          [-1, 128, 28, 28]             256\n",
      "           Conv2d-24          [-1, 128, 28, 28]           8,192\n",
      "      BatchNorm2d-25          [-1, 128, 28, 28]             256\n",
      "             ReLU-26          [-1, 128, 28, 28]               0\n",
      "       BasicBlock-27          [-1, 128, 28, 28]               0\n",
      "           Conv2d-28          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-29          [-1, 128, 28, 28]             256\n",
      "             ReLU-30          [-1, 128, 28, 28]               0\n",
      "           Conv2d-31          [-1, 128, 28, 28]          16,384\n",
      "      BatchNorm2d-32          [-1, 128, 28, 28]             256\n",
      "             ReLU-33          [-1, 128, 28, 28]               0\n",
      "       BasicBlock-34          [-1, 128, 28, 28]               0\n",
      "           Conv2d-35          [-1, 256, 14, 14]         294,912\n",
      "      BatchNorm2d-36          [-1, 256, 14, 14]             512\n",
      "             ReLU-37          [-1, 256, 14, 14]               0\n",
      "           Conv2d-38          [-1, 256, 14, 14]          65,536\n",
      "      BatchNorm2d-39          [-1, 256, 14, 14]             512\n",
      "           Conv2d-40          [-1, 256, 14, 14]          32,768\n",
      "      BatchNorm2d-41          [-1, 256, 14, 14]             512\n",
      "             ReLU-42          [-1, 256, 14, 14]               0\n",
      "       BasicBlock-43          [-1, 256, 14, 14]               0\n",
      "           Conv2d-44          [-1, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-45          [-1, 256, 14, 14]             512\n",
      "             ReLU-46          [-1, 256, 14, 14]               0\n",
      "           Conv2d-47          [-1, 256, 14, 14]          65,536\n",
      "      BatchNorm2d-48          [-1, 256, 14, 14]             512\n",
      "             ReLU-49          [-1, 256, 14, 14]               0\n",
      "       BasicBlock-50          [-1, 256, 14, 14]               0\n",
      "           Conv2d-51            [-1, 512, 7, 7]       1,179,648\n",
      "      BatchNorm2d-52            [-1, 512, 7, 7]           1,024\n",
      "             ReLU-53            [-1, 512, 7, 7]               0\n",
      "           Conv2d-54            [-1, 512, 7, 7]         262,144\n",
      "      BatchNorm2d-55            [-1, 512, 7, 7]           1,024\n",
      "           Conv2d-56            [-1, 512, 7, 7]         131,072\n",
      "      BatchNorm2d-57            [-1, 512, 7, 7]           1,024\n",
      "             ReLU-58            [-1, 512, 7, 7]               0\n",
      "       BasicBlock-59            [-1, 512, 7, 7]               0\n",
      "           Conv2d-60            [-1, 512, 7, 7]       2,359,296\n",
      "      BatchNorm2d-61            [-1, 512, 7, 7]           1,024\n",
      "             ReLU-62            [-1, 512, 7, 7]               0\n",
      "           Conv2d-63            [-1, 512, 7, 7]         262,144\n",
      "      BatchNorm2d-64            [-1, 512, 7, 7]           1,024\n",
      "             ReLU-65            [-1, 512, 7, 7]               0\n",
      "       BasicBlock-66            [-1, 512, 7, 7]               0\n",
      "AdaptiveAvgPool2d-67            [-1, 512, 1, 1]               0\n",
      "           Linear-68                  [-1, 100]          51,300\n",
      "================================================================\n",
      "Total params: 5,657,252\n",
      "Trainable params: 5,657,252\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 62.79\n",
      "Params size (MB): 21.58\n",
      "Estimated Total Size (MB): 84.94\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "model = ResNet18(100)\n",
    "summary(model,(3,224,224))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### ResNet34\n",
    "----"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://miro.medium.com/v2/resize:fit:850/1*C8jf92MeHZnxnbpMkz6jkQ.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet34(nn.Module):\n",
    "    def __init__(self,classes):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.conv_layer1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=3, out_channels=64, kernel_size=7, stride=2, padding=3 ,bias=False),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU()\n",
    "            )\n",
    "        \n",
    "        self.pooling_layer = nn.MaxPool2d(kernel_size=3, stride=2,padding=1)\n",
    "\n",
    "        self.basic_block1 = nn.Sequential(\n",
    "            BasicBlock(in_channels=64,out_channels=64,stride=1,downsampling=False),\n",
    "            BasicBlock(in_channels=64,out_channels=64,stride=1,downsampling=False),\n",
    "            BasicBlock(in_channels=64,out_channels=64,stride=1,downsampling=False)\n",
    "            )\n",
    "        \n",
    "        self.basic_block2 = nn.Sequential(\n",
    "            BasicBlock(in_channels=64,out_channels=128,stride=2,downsampling=True),\n",
    "            BasicBlock(in_channels=128,out_channels=128,stride=1,downsampling=False),\n",
    "            BasicBlock(in_channels=128,out_channels=128,stride=1,downsampling=False),\n",
    "            BasicBlock(in_channels=128,out_channels=128,stride=1,downsampling=False)\n",
    "        )\n",
    "\n",
    "        self.basic_block3 = nn.Sequential(\n",
    "            BasicBlock(in_channels=128,out_channels=256,stride=2,downsampling=True),\n",
    "            BasicBlock(in_channels=256,out_channels=256,stride=1,downsampling=False),\n",
    "            BasicBlock(in_channels=256,out_channels=256,stride=1,downsampling=False),\n",
    "            BasicBlock(in_channels=256,out_channels=256,stride=1,downsampling=False),\n",
    "            BasicBlock(in_channels=256,out_channels=256,stride=1,downsampling=False),\n",
    "            BasicBlock(in_channels=256,out_channels=256,stride=1,downsampling=False)\n",
    "        )\n",
    "\n",
    "        self.basic_block4 = nn.Sequential(\n",
    "            BasicBlock(in_channels=256,out_channels=512,stride=2,downsampling=True),\n",
    "            BasicBlock(in_channels=512,out_channels=512,stride=1,downsampling=False),\n",
    "            BasicBlock(in_channels=512,out_channels=512,stride=1,downsampling=False),\n",
    "        )\n",
    "\n",
    "        self.avg_pooling_layer = nn.AdaptiveAvgPool2d(output_size=(1,1))\n",
    "        self.output_layer = nn.Linear(512,classes)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        x = self.conv_layer1(x)\n",
    "        x = self.pooling_layer(x)\n",
    "        x = self.basic_block1(x)\n",
    "        x = self.basic_block2(x)\n",
    "        x = self.basic_block3(x)\n",
    "        x = self.basic_block4(x)\n",
    "        x = self.avg_pooling_layer(x)\n",
    "        x = x.view(x.shape[0],-1)\n",
    "        x = self.output_layer(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 64, 112, 112]           9,408\n",
      "       BatchNorm2d-2         [-1, 64, 112, 112]             128\n",
      "              ReLU-3         [-1, 64, 112, 112]               0\n",
      "         MaxPool2d-4           [-1, 64, 56, 56]               0\n",
      "            Conv2d-5           [-1, 64, 56, 56]          36,864\n",
      "       BatchNorm2d-6           [-1, 64, 56, 56]             128\n",
      "              ReLU-7           [-1, 64, 56, 56]               0\n",
      "            Conv2d-8           [-1, 64, 56, 56]           4,096\n",
      "       BatchNorm2d-9           [-1, 64, 56, 56]             128\n",
      "             ReLU-10           [-1, 64, 56, 56]               0\n",
      "       BasicBlock-11           [-1, 64, 56, 56]               0\n",
      "           Conv2d-12           [-1, 64, 56, 56]          36,864\n",
      "      BatchNorm2d-13           [-1, 64, 56, 56]             128\n",
      "             ReLU-14           [-1, 64, 56, 56]               0\n",
      "           Conv2d-15           [-1, 64, 56, 56]           4,096\n",
      "      BatchNorm2d-16           [-1, 64, 56, 56]             128\n",
      "             ReLU-17           [-1, 64, 56, 56]               0\n",
      "       BasicBlock-18           [-1, 64, 56, 56]               0\n",
      "           Conv2d-19           [-1, 64, 56, 56]          36,864\n",
      "      BatchNorm2d-20           [-1, 64, 56, 56]             128\n",
      "             ReLU-21           [-1, 64, 56, 56]               0\n",
      "           Conv2d-22           [-1, 64, 56, 56]           4,096\n",
      "      BatchNorm2d-23           [-1, 64, 56, 56]             128\n",
      "             ReLU-24           [-1, 64, 56, 56]               0\n",
      "       BasicBlock-25           [-1, 64, 56, 56]               0\n",
      "           Conv2d-26          [-1, 128, 28, 28]          73,728\n",
      "      BatchNorm2d-27          [-1, 128, 28, 28]             256\n",
      "             ReLU-28          [-1, 128, 28, 28]               0\n",
      "           Conv2d-29          [-1, 128, 28, 28]          16,384\n",
      "      BatchNorm2d-30          [-1, 128, 28, 28]             256\n",
      "           Conv2d-31          [-1, 128, 28, 28]           8,192\n",
      "      BatchNorm2d-32          [-1, 128, 28, 28]             256\n",
      "             ReLU-33          [-1, 128, 28, 28]               0\n",
      "       BasicBlock-34          [-1, 128, 28, 28]               0\n",
      "           Conv2d-35          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-36          [-1, 128, 28, 28]             256\n",
      "             ReLU-37          [-1, 128, 28, 28]               0\n",
      "           Conv2d-38          [-1, 128, 28, 28]          16,384\n",
      "      BatchNorm2d-39          [-1, 128, 28, 28]             256\n",
      "             ReLU-40          [-1, 128, 28, 28]               0\n",
      "       BasicBlock-41          [-1, 128, 28, 28]               0\n",
      "           Conv2d-42          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-43          [-1, 128, 28, 28]             256\n",
      "             ReLU-44          [-1, 128, 28, 28]               0\n",
      "           Conv2d-45          [-1, 128, 28, 28]          16,384\n",
      "      BatchNorm2d-46          [-1, 128, 28, 28]             256\n",
      "             ReLU-47          [-1, 128, 28, 28]               0\n",
      "       BasicBlock-48          [-1, 128, 28, 28]               0\n",
      "           Conv2d-49          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-50          [-1, 128, 28, 28]             256\n",
      "             ReLU-51          [-1, 128, 28, 28]               0\n",
      "           Conv2d-52          [-1, 128, 28, 28]          16,384\n",
      "      BatchNorm2d-53          [-1, 128, 28, 28]             256\n",
      "             ReLU-54          [-1, 128, 28, 28]               0\n",
      "       BasicBlock-55          [-1, 128, 28, 28]               0\n",
      "           Conv2d-56          [-1, 256, 14, 14]         294,912\n",
      "      BatchNorm2d-57          [-1, 256, 14, 14]             512\n",
      "             ReLU-58          [-1, 256, 14, 14]               0\n",
      "           Conv2d-59          [-1, 256, 14, 14]          65,536\n",
      "      BatchNorm2d-60          [-1, 256, 14, 14]             512\n",
      "           Conv2d-61          [-1, 256, 14, 14]          32,768\n",
      "      BatchNorm2d-62          [-1, 256, 14, 14]             512\n",
      "             ReLU-63          [-1, 256, 14, 14]               0\n",
      "       BasicBlock-64          [-1, 256, 14, 14]               0\n",
      "           Conv2d-65          [-1, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-66          [-1, 256, 14, 14]             512\n",
      "             ReLU-67          [-1, 256, 14, 14]               0\n",
      "           Conv2d-68          [-1, 256, 14, 14]          65,536\n",
      "      BatchNorm2d-69          [-1, 256, 14, 14]             512\n",
      "             ReLU-70          [-1, 256, 14, 14]               0\n",
      "       BasicBlock-71          [-1, 256, 14, 14]               0\n",
      "           Conv2d-72          [-1, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-73          [-1, 256, 14, 14]             512\n",
      "             ReLU-74          [-1, 256, 14, 14]               0\n",
      "           Conv2d-75          [-1, 256, 14, 14]          65,536\n",
      "      BatchNorm2d-76          [-1, 256, 14, 14]             512\n",
      "             ReLU-77          [-1, 256, 14, 14]               0\n",
      "       BasicBlock-78          [-1, 256, 14, 14]               0\n",
      "           Conv2d-79          [-1, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-80          [-1, 256, 14, 14]             512\n",
      "             ReLU-81          [-1, 256, 14, 14]               0\n",
      "           Conv2d-82          [-1, 256, 14, 14]          65,536\n",
      "      BatchNorm2d-83          [-1, 256, 14, 14]             512\n",
      "             ReLU-84          [-1, 256, 14, 14]               0\n",
      "       BasicBlock-85          [-1, 256, 14, 14]               0\n",
      "           Conv2d-86          [-1, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-87          [-1, 256, 14, 14]             512\n",
      "             ReLU-88          [-1, 256, 14, 14]               0\n",
      "           Conv2d-89          [-1, 256, 14, 14]          65,536\n",
      "      BatchNorm2d-90          [-1, 256, 14, 14]             512\n",
      "             ReLU-91          [-1, 256, 14, 14]               0\n",
      "       BasicBlock-92          [-1, 256, 14, 14]               0\n",
      "           Conv2d-93          [-1, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-94          [-1, 256, 14, 14]             512\n",
      "             ReLU-95          [-1, 256, 14, 14]               0\n",
      "           Conv2d-96          [-1, 256, 14, 14]          65,536\n",
      "      BatchNorm2d-97          [-1, 256, 14, 14]             512\n",
      "             ReLU-98          [-1, 256, 14, 14]               0\n",
      "       BasicBlock-99          [-1, 256, 14, 14]               0\n",
      "          Conv2d-100            [-1, 512, 7, 7]       1,179,648\n",
      "     BatchNorm2d-101            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-102            [-1, 512, 7, 7]               0\n",
      "          Conv2d-103            [-1, 512, 7, 7]         262,144\n",
      "     BatchNorm2d-104            [-1, 512, 7, 7]           1,024\n",
      "          Conv2d-105            [-1, 512, 7, 7]         131,072\n",
      "     BatchNorm2d-106            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-107            [-1, 512, 7, 7]               0\n",
      "      BasicBlock-108            [-1, 512, 7, 7]               0\n",
      "          Conv2d-109            [-1, 512, 7, 7]       2,359,296\n",
      "     BatchNorm2d-110            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-111            [-1, 512, 7, 7]               0\n",
      "          Conv2d-112            [-1, 512, 7, 7]         262,144\n",
      "     BatchNorm2d-113            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-114            [-1, 512, 7, 7]               0\n",
      "      BasicBlock-115            [-1, 512, 7, 7]               0\n",
      "          Conv2d-116            [-1, 512, 7, 7]       2,359,296\n",
      "     BatchNorm2d-117            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-118            [-1, 512, 7, 7]               0\n",
      "          Conv2d-119            [-1, 512, 7, 7]         262,144\n",
      "     BatchNorm2d-120            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-121            [-1, 512, 7, 7]               0\n",
      "      BasicBlock-122            [-1, 512, 7, 7]               0\n",
      "AdaptiveAvgPool2d-123            [-1, 512, 1, 1]               0\n",
      "          Linear-124                    [-1, 2]           1,026\n",
      "================================================================\n",
      "Total params: 11,225,922\n",
      "Trainable params: 11,225,922\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 96.28\n",
      "Params size (MB): 42.82\n",
      "Estimated Total Size (MB): 139.68\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "model = ResNet34(2)\n",
    "summary(model,(3,224,224))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### ResNet50\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet50(nn.Module):\n",
    "    def __init__(self,classes):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.conv_layer1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=3, out_channels=64, kernel_size=7, stride=2, padding=3 ,bias=False),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU()\n",
    "            )\n",
    "        \n",
    "        self.pooling_layer = nn.MaxPool2d(kernel_size=3, stride=2,padding=1)\n",
    "\n",
    "        self.bottleneck_block1 = nn.Sequential(\n",
    "            Bottleneck(in_channels=64,out_channels=64,stride=1,downsampling=True),\n",
    "            Bottleneck(in_channels=256,out_channels=64,stride=1,downsampling=False),\n",
    "            Bottleneck(in_channels=256,out_channels=64,stride=1,downsampling=False)\n",
    "            )\n",
    "        \n",
    "        self.bottleneck_block2 = nn.Sequential(\n",
    "            Bottleneck(in_channels=256,out_channels=128,stride=2,downsampling=True),\n",
    "            Bottleneck(in_channels=512,out_channels=128,stride=1,downsampling=False),\n",
    "            Bottleneck(in_channels=512,out_channels=128,stride=1,downsampling=False),\n",
    "            Bottleneck(in_channels=512,out_channels=128,stride=1,downsampling=False)\n",
    "        )\n",
    "\n",
    "        self.bottleneck_block3 = nn.Sequential(\n",
    "            Bottleneck(in_channels=512,out_channels=256,stride=2,downsampling=True),\n",
    "            Bottleneck(in_channels=1024,out_channels=256,stride=1,downsampling=False),\n",
    "            Bottleneck(in_channels=1024,out_channels=256,stride=1,downsampling=False),\n",
    "            Bottleneck(in_channels=1024,out_channels=256,stride=1,downsampling=False),\n",
    "            Bottleneck(in_channels=1024,out_channels=256,stride=1,downsampling=False),\n",
    "            Bottleneck(in_channels=1024,out_channels=256,stride=1,downsampling=False),\n",
    "        )\n",
    "\n",
    "        self.bottleneck_block4 = nn.Sequential(\n",
    "            Bottleneck(in_channels=1024,out_channels=512,stride=2,downsampling=True),\n",
    "            Bottleneck(in_channels=2048,out_channels=512,stride=1,downsampling=False),\n",
    "            Bottleneck(in_channels=2048,out_channels=512,stride=1,downsampling=False)\n",
    "        )\n",
    "\n",
    "        self.avg_pooling_layer = nn.AdaptiveAvgPool2d(output_size=(1,1))\n",
    "        self.output_layer = nn.Linear(2048,classes)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        x = self.conv_layer1(x)\n",
    "        x = self.pooling_layer(x)\n",
    "        x = self.bottleneck_block1(x)\n",
    "        x = self.bottleneck_block2(x)\n",
    "        x = self.bottleneck_block3(x)\n",
    "        x = self.bottleneck_block4(x)\n",
    "        x = self.avg_pooling_layer(x)\n",
    "        x = x.view(x.shape[0],-1)\n",
    "        x = self.output_layer(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 64, 112, 112]           9,408\n",
      "       BatchNorm2d-2         [-1, 64, 112, 112]             128\n",
      "              ReLU-3         [-1, 64, 112, 112]               0\n",
      "         MaxPool2d-4           [-1, 64, 56, 56]               0\n",
      "            Conv2d-5           [-1, 64, 56, 56]           4,096\n",
      "       BatchNorm2d-6           [-1, 64, 56, 56]             128\n",
      "              ReLU-7           [-1, 64, 56, 56]               0\n",
      "            Conv2d-8           [-1, 64, 56, 56]          36,864\n",
      "       BatchNorm2d-9           [-1, 64, 56, 56]             128\n",
      "             ReLU-10           [-1, 64, 56, 56]               0\n",
      "           Conv2d-11          [-1, 256, 56, 56]          16,384\n",
      "      BatchNorm2d-12          [-1, 256, 56, 56]             512\n",
      "           Conv2d-13          [-1, 256, 56, 56]          16,384\n",
      "      BatchNorm2d-14          [-1, 256, 56, 56]             512\n",
      "             ReLU-15          [-1, 256, 56, 56]               0\n",
      "       Bottleneck-16          [-1, 256, 56, 56]               0\n",
      "           Conv2d-17           [-1, 64, 56, 56]          16,384\n",
      "      BatchNorm2d-18           [-1, 64, 56, 56]             128\n",
      "             ReLU-19           [-1, 64, 56, 56]               0\n",
      "           Conv2d-20           [-1, 64, 56, 56]          36,864\n",
      "      BatchNorm2d-21           [-1, 64, 56, 56]             128\n",
      "             ReLU-22           [-1, 64, 56, 56]               0\n",
      "           Conv2d-23          [-1, 256, 56, 56]          16,384\n",
      "      BatchNorm2d-24          [-1, 256, 56, 56]             512\n",
      "             ReLU-25          [-1, 256, 56, 56]               0\n",
      "       Bottleneck-26          [-1, 256, 56, 56]               0\n",
      "           Conv2d-27           [-1, 64, 56, 56]          16,384\n",
      "      BatchNorm2d-28           [-1, 64, 56, 56]             128\n",
      "             ReLU-29           [-1, 64, 56, 56]               0\n",
      "           Conv2d-30           [-1, 64, 56, 56]          36,864\n",
      "      BatchNorm2d-31           [-1, 64, 56, 56]             128\n",
      "             ReLU-32           [-1, 64, 56, 56]               0\n",
      "           Conv2d-33          [-1, 256, 56, 56]          16,384\n",
      "      BatchNorm2d-34          [-1, 256, 56, 56]             512\n",
      "             ReLU-35          [-1, 256, 56, 56]               0\n",
      "       Bottleneck-36          [-1, 256, 56, 56]               0\n",
      "           Conv2d-37          [-1, 128, 56, 56]          32,768\n",
      "      BatchNorm2d-38          [-1, 128, 56, 56]             256\n",
      "             ReLU-39          [-1, 128, 56, 56]               0\n",
      "           Conv2d-40          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-41          [-1, 128, 28, 28]             256\n",
      "             ReLU-42          [-1, 128, 28, 28]               0\n",
      "           Conv2d-43          [-1, 512, 28, 28]          65,536\n",
      "      BatchNorm2d-44          [-1, 512, 28, 28]           1,024\n",
      "           Conv2d-45          [-1, 512, 28, 28]         131,072\n",
      "      BatchNorm2d-46          [-1, 512, 28, 28]           1,024\n",
      "             ReLU-47          [-1, 512, 28, 28]               0\n",
      "       Bottleneck-48          [-1, 512, 28, 28]               0\n",
      "           Conv2d-49          [-1, 128, 28, 28]          65,536\n",
      "      BatchNorm2d-50          [-1, 128, 28, 28]             256\n",
      "             ReLU-51          [-1, 128, 28, 28]               0\n",
      "           Conv2d-52          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-53          [-1, 128, 28, 28]             256\n",
      "             ReLU-54          [-1, 128, 28, 28]               0\n",
      "           Conv2d-55          [-1, 512, 28, 28]          65,536\n",
      "      BatchNorm2d-56          [-1, 512, 28, 28]           1,024\n",
      "             ReLU-57          [-1, 512, 28, 28]               0\n",
      "       Bottleneck-58          [-1, 512, 28, 28]               0\n",
      "           Conv2d-59          [-1, 128, 28, 28]          65,536\n",
      "      BatchNorm2d-60          [-1, 128, 28, 28]             256\n",
      "             ReLU-61          [-1, 128, 28, 28]               0\n",
      "           Conv2d-62          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-63          [-1, 128, 28, 28]             256\n",
      "             ReLU-64          [-1, 128, 28, 28]               0\n",
      "           Conv2d-65          [-1, 512, 28, 28]          65,536\n",
      "      BatchNorm2d-66          [-1, 512, 28, 28]           1,024\n",
      "             ReLU-67          [-1, 512, 28, 28]               0\n",
      "       Bottleneck-68          [-1, 512, 28, 28]               0\n",
      "           Conv2d-69          [-1, 128, 28, 28]          65,536\n",
      "      BatchNorm2d-70          [-1, 128, 28, 28]             256\n",
      "             ReLU-71          [-1, 128, 28, 28]               0\n",
      "           Conv2d-72          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-73          [-1, 128, 28, 28]             256\n",
      "             ReLU-74          [-1, 128, 28, 28]               0\n",
      "           Conv2d-75          [-1, 512, 28, 28]          65,536\n",
      "      BatchNorm2d-76          [-1, 512, 28, 28]           1,024\n",
      "             ReLU-77          [-1, 512, 28, 28]               0\n",
      "       Bottleneck-78          [-1, 512, 28, 28]               0\n",
      "           Conv2d-79          [-1, 256, 28, 28]         131,072\n",
      "      BatchNorm2d-80          [-1, 256, 28, 28]             512\n",
      "             ReLU-81          [-1, 256, 28, 28]               0\n",
      "           Conv2d-82          [-1, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-83          [-1, 256, 14, 14]             512\n",
      "             ReLU-84          [-1, 256, 14, 14]               0\n",
      "           Conv2d-85         [-1, 1024, 14, 14]         262,144\n",
      "      BatchNorm2d-86         [-1, 1024, 14, 14]           2,048\n",
      "           Conv2d-87         [-1, 1024, 14, 14]         524,288\n",
      "      BatchNorm2d-88         [-1, 1024, 14, 14]           2,048\n",
      "             ReLU-89         [-1, 1024, 14, 14]               0\n",
      "       Bottleneck-90         [-1, 1024, 14, 14]               0\n",
      "           Conv2d-91          [-1, 256, 14, 14]         262,144\n",
      "      BatchNorm2d-92          [-1, 256, 14, 14]             512\n",
      "             ReLU-93          [-1, 256, 14, 14]               0\n",
      "           Conv2d-94          [-1, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-95          [-1, 256, 14, 14]             512\n",
      "             ReLU-96          [-1, 256, 14, 14]               0\n",
      "           Conv2d-97         [-1, 1024, 14, 14]         262,144\n",
      "      BatchNorm2d-98         [-1, 1024, 14, 14]           2,048\n",
      "             ReLU-99         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-100         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-101          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-102          [-1, 256, 14, 14]             512\n",
      "            ReLU-103          [-1, 256, 14, 14]               0\n",
      "          Conv2d-104          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-105          [-1, 256, 14, 14]             512\n",
      "            ReLU-106          [-1, 256, 14, 14]               0\n",
      "          Conv2d-107         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-108         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-109         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-110         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-111          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-112          [-1, 256, 14, 14]             512\n",
      "            ReLU-113          [-1, 256, 14, 14]               0\n",
      "          Conv2d-114          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-115          [-1, 256, 14, 14]             512\n",
      "            ReLU-116          [-1, 256, 14, 14]               0\n",
      "          Conv2d-117         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-118         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-119         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-120         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-121          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-122          [-1, 256, 14, 14]             512\n",
      "            ReLU-123          [-1, 256, 14, 14]               0\n",
      "          Conv2d-124          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-125          [-1, 256, 14, 14]             512\n",
      "            ReLU-126          [-1, 256, 14, 14]               0\n",
      "          Conv2d-127         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-128         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-129         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-130         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-131          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-132          [-1, 256, 14, 14]             512\n",
      "            ReLU-133          [-1, 256, 14, 14]               0\n",
      "          Conv2d-134          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-135          [-1, 256, 14, 14]             512\n",
      "            ReLU-136          [-1, 256, 14, 14]               0\n",
      "          Conv2d-137         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-138         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-139         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-140         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-141          [-1, 512, 14, 14]         524,288\n",
      "     BatchNorm2d-142          [-1, 512, 14, 14]           1,024\n",
      "            ReLU-143          [-1, 512, 14, 14]               0\n",
      "          Conv2d-144            [-1, 512, 7, 7]       2,359,296\n",
      "     BatchNorm2d-145            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-146            [-1, 512, 7, 7]               0\n",
      "          Conv2d-147           [-1, 2048, 7, 7]       1,048,576\n",
      "     BatchNorm2d-148           [-1, 2048, 7, 7]           4,096\n",
      "          Conv2d-149           [-1, 2048, 7, 7]       2,097,152\n",
      "     BatchNorm2d-150           [-1, 2048, 7, 7]           4,096\n",
      "            ReLU-151           [-1, 2048, 7, 7]               0\n",
      "      Bottleneck-152           [-1, 2048, 7, 7]               0\n",
      "          Conv2d-153            [-1, 512, 7, 7]       1,048,576\n",
      "     BatchNorm2d-154            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-155            [-1, 512, 7, 7]               0\n",
      "          Conv2d-156            [-1, 512, 7, 7]       2,359,296\n",
      "     BatchNorm2d-157            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-158            [-1, 512, 7, 7]               0\n",
      "          Conv2d-159           [-1, 2048, 7, 7]       1,048,576\n",
      "     BatchNorm2d-160           [-1, 2048, 7, 7]           4,096\n",
      "            ReLU-161           [-1, 2048, 7, 7]               0\n",
      "      Bottleneck-162           [-1, 2048, 7, 7]               0\n",
      "          Conv2d-163            [-1, 512, 7, 7]       1,048,576\n",
      "     BatchNorm2d-164            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-165            [-1, 512, 7, 7]               0\n",
      "          Conv2d-166            [-1, 512, 7, 7]       2,359,296\n",
      "     BatchNorm2d-167            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-168            [-1, 512, 7, 7]               0\n",
      "          Conv2d-169           [-1, 2048, 7, 7]       1,048,576\n",
      "     BatchNorm2d-170           [-1, 2048, 7, 7]           4,096\n",
      "            ReLU-171           [-1, 2048, 7, 7]               0\n",
      "      Bottleneck-172           [-1, 2048, 7, 7]               0\n",
      "AdaptiveAvgPool2d-173           [-1, 2048, 1, 1]               0\n",
      "          Linear-174                    [-1, 4]           8,196\n",
      "================================================================\n",
      "Total params: 23,516,228\n",
      "Trainable params: 23,516,228\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 286.55\n",
      "Params size (MB): 89.71\n",
      "Estimated Total Size (MB): 376.83\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "model = ResNet50(4)\n",
    "summary(model,(3,224,224))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### ResNet101\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet101(nn.Module):\n",
    "    def __init__(self,classes):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.conv_layer1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=3, out_channels=64, kernel_size=7, stride=2, padding=3 ,bias=False),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU()\n",
    "            )\n",
    "        \n",
    "        self.pooling_layer = nn.MaxPool2d(kernel_size=3, stride=2,padding=1)\n",
    "\n",
    "        self.bottleneck_block1 = nn.Sequential(\n",
    "            Bottleneck(in_channels=64,out_channels=64,stride=1,downsampling=True),\n",
    "            Bottleneck(in_channels=256,out_channels=64,stride=1,downsampling=False),\n",
    "            Bottleneck(in_channels=256,out_channels=64,stride=1,downsampling=False)\n",
    "            )\n",
    "        \n",
    "        self.bottleneck_block2 = nn.Sequential(\n",
    "            Bottleneck(in_channels=256,out_channels=128,stride=2,downsampling=True),\n",
    "            Bottleneck(in_channels=512,out_channels=128,stride=1,downsampling=False),\n",
    "            Bottleneck(in_channels=512,out_channels=128,stride=1,downsampling=False),\n",
    "            Bottleneck(in_channels=512,out_channels=128,stride=1,downsampling=False)\n",
    "        )\n",
    "\n",
    "        block3_configuration = list()\n",
    "        for iteration in range(23):\n",
    "            if iteration == 0:\n",
    "                block3_configuration.append(Bottleneck(in_channels=512,out_channels=256,stride=2,downsampling=True))\n",
    "            else:\n",
    "                block3_configuration.append(Bottleneck(in_channels=1024,out_channels=256,stride=1,downsampling=False))\n",
    "\n",
    "        self.bottleneck_block3 = nn.Sequential(*block3_configuration)\n",
    "\n",
    "        self.bottleneck_block4 = nn.Sequential(\n",
    "            Bottleneck(in_channels=1024,out_channels=512,stride=2,downsampling=True),\n",
    "            Bottleneck(in_channels=2048,out_channels=512,stride=1,downsampling=False),\n",
    "            Bottleneck(in_channels=2048,out_channels=512,stride=1,downsampling=False)\n",
    "        )\n",
    "\n",
    "        self.avg_pooling_layer = nn.AdaptiveAvgPool2d(output_size=(1,1))\n",
    "        self.output_layer = nn.Linear(2048,classes)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        x = self.conv_layer1(x)\n",
    "        x = self.pooling_layer(x)\n",
    "        x = self.bottleneck_block1(x)\n",
    "        x = self.bottleneck_block2(x)\n",
    "        x = self.bottleneck_block3(x)\n",
    "        x = self.bottleneck_block4(x)\n",
    "        x = self.avg_pooling_layer(x)\n",
    "        x = x.view(x.shape[0],-1)\n",
    "        x = self.output_layer(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 64, 112, 112]           9,408\n",
      "       BatchNorm2d-2         [-1, 64, 112, 112]             128\n",
      "              ReLU-3         [-1, 64, 112, 112]               0\n",
      "         MaxPool2d-4           [-1, 64, 56, 56]               0\n",
      "            Conv2d-5           [-1, 64, 56, 56]           4,096\n",
      "       BatchNorm2d-6           [-1, 64, 56, 56]             128\n",
      "              ReLU-7           [-1, 64, 56, 56]               0\n",
      "            Conv2d-8           [-1, 64, 56, 56]          36,864\n",
      "       BatchNorm2d-9           [-1, 64, 56, 56]             128\n",
      "             ReLU-10           [-1, 64, 56, 56]               0\n",
      "           Conv2d-11          [-1, 256, 56, 56]          16,384\n",
      "      BatchNorm2d-12          [-1, 256, 56, 56]             512\n",
      "           Conv2d-13          [-1, 256, 56, 56]          16,384\n",
      "      BatchNorm2d-14          [-1, 256, 56, 56]             512\n",
      "             ReLU-15          [-1, 256, 56, 56]               0\n",
      "       Bottleneck-16          [-1, 256, 56, 56]               0\n",
      "           Conv2d-17           [-1, 64, 56, 56]          16,384\n",
      "      BatchNorm2d-18           [-1, 64, 56, 56]             128\n",
      "             ReLU-19           [-1, 64, 56, 56]               0\n",
      "           Conv2d-20           [-1, 64, 56, 56]          36,864\n",
      "      BatchNorm2d-21           [-1, 64, 56, 56]             128\n",
      "             ReLU-22           [-1, 64, 56, 56]               0\n",
      "           Conv2d-23          [-1, 256, 56, 56]          16,384\n",
      "      BatchNorm2d-24          [-1, 256, 56, 56]             512\n",
      "             ReLU-25          [-1, 256, 56, 56]               0\n",
      "       Bottleneck-26          [-1, 256, 56, 56]               0\n",
      "           Conv2d-27           [-1, 64, 56, 56]          16,384\n",
      "      BatchNorm2d-28           [-1, 64, 56, 56]             128\n",
      "             ReLU-29           [-1, 64, 56, 56]               0\n",
      "           Conv2d-30           [-1, 64, 56, 56]          36,864\n",
      "      BatchNorm2d-31           [-1, 64, 56, 56]             128\n",
      "             ReLU-32           [-1, 64, 56, 56]               0\n",
      "           Conv2d-33          [-1, 256, 56, 56]          16,384\n",
      "      BatchNorm2d-34          [-1, 256, 56, 56]             512\n",
      "             ReLU-35          [-1, 256, 56, 56]               0\n",
      "       Bottleneck-36          [-1, 256, 56, 56]               0\n",
      "           Conv2d-37          [-1, 128, 56, 56]          32,768\n",
      "      BatchNorm2d-38          [-1, 128, 56, 56]             256\n",
      "             ReLU-39          [-1, 128, 56, 56]               0\n",
      "           Conv2d-40          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-41          [-1, 128, 28, 28]             256\n",
      "             ReLU-42          [-1, 128, 28, 28]               0\n",
      "           Conv2d-43          [-1, 512, 28, 28]          65,536\n",
      "      BatchNorm2d-44          [-1, 512, 28, 28]           1,024\n",
      "           Conv2d-45          [-1, 512, 28, 28]         131,072\n",
      "      BatchNorm2d-46          [-1, 512, 28, 28]           1,024\n",
      "             ReLU-47          [-1, 512, 28, 28]               0\n",
      "       Bottleneck-48          [-1, 512, 28, 28]               0\n",
      "           Conv2d-49          [-1, 128, 28, 28]          65,536\n",
      "      BatchNorm2d-50          [-1, 128, 28, 28]             256\n",
      "             ReLU-51          [-1, 128, 28, 28]               0\n",
      "           Conv2d-52          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-53          [-1, 128, 28, 28]             256\n",
      "             ReLU-54          [-1, 128, 28, 28]               0\n",
      "           Conv2d-55          [-1, 512, 28, 28]          65,536\n",
      "      BatchNorm2d-56          [-1, 512, 28, 28]           1,024\n",
      "             ReLU-57          [-1, 512, 28, 28]               0\n",
      "       Bottleneck-58          [-1, 512, 28, 28]               0\n",
      "           Conv2d-59          [-1, 128, 28, 28]          65,536\n",
      "      BatchNorm2d-60          [-1, 128, 28, 28]             256\n",
      "             ReLU-61          [-1, 128, 28, 28]               0\n",
      "           Conv2d-62          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-63          [-1, 128, 28, 28]             256\n",
      "             ReLU-64          [-1, 128, 28, 28]               0\n",
      "           Conv2d-65          [-1, 512, 28, 28]          65,536\n",
      "      BatchNorm2d-66          [-1, 512, 28, 28]           1,024\n",
      "             ReLU-67          [-1, 512, 28, 28]               0\n",
      "       Bottleneck-68          [-1, 512, 28, 28]               0\n",
      "           Conv2d-69          [-1, 128, 28, 28]          65,536\n",
      "      BatchNorm2d-70          [-1, 128, 28, 28]             256\n",
      "             ReLU-71          [-1, 128, 28, 28]               0\n",
      "           Conv2d-72          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-73          [-1, 128, 28, 28]             256\n",
      "             ReLU-74          [-1, 128, 28, 28]               0\n",
      "           Conv2d-75          [-1, 512, 28, 28]          65,536\n",
      "      BatchNorm2d-76          [-1, 512, 28, 28]           1,024\n",
      "             ReLU-77          [-1, 512, 28, 28]               0\n",
      "       Bottleneck-78          [-1, 512, 28, 28]               0\n",
      "           Conv2d-79          [-1, 256, 28, 28]         131,072\n",
      "      BatchNorm2d-80          [-1, 256, 28, 28]             512\n",
      "             ReLU-81          [-1, 256, 28, 28]               0\n",
      "           Conv2d-82          [-1, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-83          [-1, 256, 14, 14]             512\n",
      "             ReLU-84          [-1, 256, 14, 14]               0\n",
      "           Conv2d-85         [-1, 1024, 14, 14]         262,144\n",
      "      BatchNorm2d-86         [-1, 1024, 14, 14]           2,048\n",
      "           Conv2d-87         [-1, 1024, 14, 14]         524,288\n",
      "      BatchNorm2d-88         [-1, 1024, 14, 14]           2,048\n",
      "             ReLU-89         [-1, 1024, 14, 14]               0\n",
      "       Bottleneck-90         [-1, 1024, 14, 14]               0\n",
      "           Conv2d-91          [-1, 256, 14, 14]         262,144\n",
      "      BatchNorm2d-92          [-1, 256, 14, 14]             512\n",
      "             ReLU-93          [-1, 256, 14, 14]               0\n",
      "           Conv2d-94          [-1, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-95          [-1, 256, 14, 14]             512\n",
      "             ReLU-96          [-1, 256, 14, 14]               0\n",
      "           Conv2d-97         [-1, 1024, 14, 14]         262,144\n",
      "      BatchNorm2d-98         [-1, 1024, 14, 14]           2,048\n",
      "             ReLU-99         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-100         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-101          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-102          [-1, 256, 14, 14]             512\n",
      "            ReLU-103          [-1, 256, 14, 14]               0\n",
      "          Conv2d-104          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-105          [-1, 256, 14, 14]             512\n",
      "            ReLU-106          [-1, 256, 14, 14]               0\n",
      "          Conv2d-107         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-108         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-109         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-110         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-111          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-112          [-1, 256, 14, 14]             512\n",
      "            ReLU-113          [-1, 256, 14, 14]               0\n",
      "          Conv2d-114          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-115          [-1, 256, 14, 14]             512\n",
      "            ReLU-116          [-1, 256, 14, 14]               0\n",
      "          Conv2d-117         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-118         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-119         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-120         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-121          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-122          [-1, 256, 14, 14]             512\n",
      "            ReLU-123          [-1, 256, 14, 14]               0\n",
      "          Conv2d-124          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-125          [-1, 256, 14, 14]             512\n",
      "            ReLU-126          [-1, 256, 14, 14]               0\n",
      "          Conv2d-127         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-128         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-129         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-130         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-131          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-132          [-1, 256, 14, 14]             512\n",
      "            ReLU-133          [-1, 256, 14, 14]               0\n",
      "          Conv2d-134          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-135          [-1, 256, 14, 14]             512\n",
      "            ReLU-136          [-1, 256, 14, 14]               0\n",
      "          Conv2d-137         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-138         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-139         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-140         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-141          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-142          [-1, 256, 14, 14]             512\n",
      "            ReLU-143          [-1, 256, 14, 14]               0\n",
      "          Conv2d-144          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-145          [-1, 256, 14, 14]             512\n",
      "            ReLU-146          [-1, 256, 14, 14]               0\n",
      "          Conv2d-147         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-148         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-149         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-150         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-151          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-152          [-1, 256, 14, 14]             512\n",
      "            ReLU-153          [-1, 256, 14, 14]               0\n",
      "          Conv2d-154          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-155          [-1, 256, 14, 14]             512\n",
      "            ReLU-156          [-1, 256, 14, 14]               0\n",
      "          Conv2d-157         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-158         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-159         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-160         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-161          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-162          [-1, 256, 14, 14]             512\n",
      "            ReLU-163          [-1, 256, 14, 14]               0\n",
      "          Conv2d-164          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-165          [-1, 256, 14, 14]             512\n",
      "            ReLU-166          [-1, 256, 14, 14]               0\n",
      "          Conv2d-167         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-168         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-169         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-170         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-171          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-172          [-1, 256, 14, 14]             512\n",
      "            ReLU-173          [-1, 256, 14, 14]               0\n",
      "          Conv2d-174          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-175          [-1, 256, 14, 14]             512\n",
      "            ReLU-176          [-1, 256, 14, 14]               0\n",
      "          Conv2d-177         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-178         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-179         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-180         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-181          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-182          [-1, 256, 14, 14]             512\n",
      "            ReLU-183          [-1, 256, 14, 14]               0\n",
      "          Conv2d-184          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-185          [-1, 256, 14, 14]             512\n",
      "            ReLU-186          [-1, 256, 14, 14]               0\n",
      "          Conv2d-187         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-188         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-189         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-190         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-191          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-192          [-1, 256, 14, 14]             512\n",
      "            ReLU-193          [-1, 256, 14, 14]               0\n",
      "          Conv2d-194          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-195          [-1, 256, 14, 14]             512\n",
      "            ReLU-196          [-1, 256, 14, 14]               0\n",
      "          Conv2d-197         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-198         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-199         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-200         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-201          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-202          [-1, 256, 14, 14]             512\n",
      "            ReLU-203          [-1, 256, 14, 14]               0\n",
      "          Conv2d-204          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-205          [-1, 256, 14, 14]             512\n",
      "            ReLU-206          [-1, 256, 14, 14]               0\n",
      "          Conv2d-207         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-208         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-209         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-210         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-211          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-212          [-1, 256, 14, 14]             512\n",
      "            ReLU-213          [-1, 256, 14, 14]               0\n",
      "          Conv2d-214          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-215          [-1, 256, 14, 14]             512\n",
      "            ReLU-216          [-1, 256, 14, 14]               0\n",
      "          Conv2d-217         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-218         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-219         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-220         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-221          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-222          [-1, 256, 14, 14]             512\n",
      "            ReLU-223          [-1, 256, 14, 14]               0\n",
      "          Conv2d-224          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-225          [-1, 256, 14, 14]             512\n",
      "            ReLU-226          [-1, 256, 14, 14]               0\n",
      "          Conv2d-227         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-228         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-229         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-230         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-231          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-232          [-1, 256, 14, 14]             512\n",
      "            ReLU-233          [-1, 256, 14, 14]               0\n",
      "          Conv2d-234          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-235          [-1, 256, 14, 14]             512\n",
      "            ReLU-236          [-1, 256, 14, 14]               0\n",
      "          Conv2d-237         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-238         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-239         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-240         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-241          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-242          [-1, 256, 14, 14]             512\n",
      "            ReLU-243          [-1, 256, 14, 14]               0\n",
      "          Conv2d-244          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-245          [-1, 256, 14, 14]             512\n",
      "            ReLU-246          [-1, 256, 14, 14]               0\n",
      "          Conv2d-247         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-248         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-249         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-250         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-251          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-252          [-1, 256, 14, 14]             512\n",
      "            ReLU-253          [-1, 256, 14, 14]               0\n",
      "          Conv2d-254          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-255          [-1, 256, 14, 14]             512\n",
      "            ReLU-256          [-1, 256, 14, 14]               0\n",
      "          Conv2d-257         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-258         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-259         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-260         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-261          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-262          [-1, 256, 14, 14]             512\n",
      "            ReLU-263          [-1, 256, 14, 14]               0\n",
      "          Conv2d-264          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-265          [-1, 256, 14, 14]             512\n",
      "            ReLU-266          [-1, 256, 14, 14]               0\n",
      "          Conv2d-267         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-268         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-269         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-270         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-271          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-272          [-1, 256, 14, 14]             512\n",
      "            ReLU-273          [-1, 256, 14, 14]               0\n",
      "          Conv2d-274          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-275          [-1, 256, 14, 14]             512\n",
      "            ReLU-276          [-1, 256, 14, 14]               0\n",
      "          Conv2d-277         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-278         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-279         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-280         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-281          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-282          [-1, 256, 14, 14]             512\n",
      "            ReLU-283          [-1, 256, 14, 14]               0\n",
      "          Conv2d-284          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-285          [-1, 256, 14, 14]             512\n",
      "            ReLU-286          [-1, 256, 14, 14]               0\n",
      "          Conv2d-287         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-288         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-289         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-290         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-291          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-292          [-1, 256, 14, 14]             512\n",
      "            ReLU-293          [-1, 256, 14, 14]               0\n",
      "          Conv2d-294          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-295          [-1, 256, 14, 14]             512\n",
      "            ReLU-296          [-1, 256, 14, 14]               0\n",
      "          Conv2d-297         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-298         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-299         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-300         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-301          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-302          [-1, 256, 14, 14]             512\n",
      "            ReLU-303          [-1, 256, 14, 14]               0\n",
      "          Conv2d-304          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-305          [-1, 256, 14, 14]             512\n",
      "            ReLU-306          [-1, 256, 14, 14]               0\n",
      "          Conv2d-307         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-308         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-309         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-310         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-311          [-1, 512, 14, 14]         524,288\n",
      "     BatchNorm2d-312          [-1, 512, 14, 14]           1,024\n",
      "            ReLU-313          [-1, 512, 14, 14]               0\n",
      "          Conv2d-314            [-1, 512, 7, 7]       2,359,296\n",
      "     BatchNorm2d-315            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-316            [-1, 512, 7, 7]               0\n",
      "          Conv2d-317           [-1, 2048, 7, 7]       1,048,576\n",
      "     BatchNorm2d-318           [-1, 2048, 7, 7]           4,096\n",
      "          Conv2d-319           [-1, 2048, 7, 7]       2,097,152\n",
      "     BatchNorm2d-320           [-1, 2048, 7, 7]           4,096\n",
      "            ReLU-321           [-1, 2048, 7, 7]               0\n",
      "      Bottleneck-322           [-1, 2048, 7, 7]               0\n",
      "          Conv2d-323            [-1, 512, 7, 7]       1,048,576\n",
      "     BatchNorm2d-324            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-325            [-1, 512, 7, 7]               0\n",
      "          Conv2d-326            [-1, 512, 7, 7]       2,359,296\n",
      "     BatchNorm2d-327            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-328            [-1, 512, 7, 7]               0\n",
      "          Conv2d-329           [-1, 2048, 7, 7]       1,048,576\n",
      "     BatchNorm2d-330           [-1, 2048, 7, 7]           4,096\n",
      "            ReLU-331           [-1, 2048, 7, 7]               0\n",
      "      Bottleneck-332           [-1, 2048, 7, 7]               0\n",
      "          Conv2d-333            [-1, 512, 7, 7]       1,048,576\n",
      "     BatchNorm2d-334            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-335            [-1, 512, 7, 7]               0\n",
      "          Conv2d-336            [-1, 512, 7, 7]       2,359,296\n",
      "     BatchNorm2d-337            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-338            [-1, 512, 7, 7]               0\n",
      "          Conv2d-339           [-1, 2048, 7, 7]       1,048,576\n",
      "     BatchNorm2d-340           [-1, 2048, 7, 7]           4,096\n",
      "            ReLU-341           [-1, 2048, 7, 7]               0\n",
      "      Bottleneck-342           [-1, 2048, 7, 7]               0\n",
      "AdaptiveAvgPool2d-343           [-1, 2048, 1, 1]               0\n",
      "          Linear-344                 [-1, 1000]       2,049,000\n",
      "================================================================\n",
      "Total params: 44,549,160\n",
      "Trainable params: 44,549,160\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 429.73\n",
      "Params size (MB): 169.94\n",
      "Estimated Total Size (MB): 600.25\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "model = ResNet101(1000)\n",
    "summary(model,(3,224,224))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### ResNet152\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet152(nn.Module):\n",
    "    def __init__(self,classes):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.conv_layer1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=3, out_channels=64, kernel_size=7, stride=2, padding=3 ,bias=False),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU()\n",
    "            )\n",
    "        \n",
    "        self.pooling_layer = nn.MaxPool2d(kernel_size=3, stride=2,padding=1)\n",
    "\n",
    "        self.bottleneck_block1 = nn.Sequential(\n",
    "            Bottleneck(in_channels=64,out_channels=64,stride=1,downsampling=True),\n",
    "            Bottleneck(in_channels=256,out_channels=64,stride=1,downsampling=False),\n",
    "            Bottleneck(in_channels=256,out_channels=64,stride=1,downsampling=False)\n",
    "            )\n",
    "        \n",
    "        self.bottleneck_block2 = nn.Sequential(\n",
    "            Bottleneck(in_channels=256,out_channels=128,stride=2,downsampling=True),\n",
    "            Bottleneck(in_channels=512,out_channels=128,stride=1,downsampling=False),\n",
    "            Bottleneck(in_channels=512,out_channels=128,stride=1,downsampling=False),\n",
    "            Bottleneck(in_channels=512,out_channels=128,stride=1,downsampling=False),\n",
    "            Bottleneck(in_channels=512,out_channels=128,stride=1,downsampling=False),\n",
    "            Bottleneck(in_channels=512,out_channels=128,stride=1,downsampling=False),\n",
    "            Bottleneck(in_channels=512,out_channels=128,stride=1,downsampling=False),\n",
    "            Bottleneck(in_channels=512,out_channels=128,stride=1,downsampling=False)\n",
    "        )\n",
    "\n",
    "        block3_configuration = list()\n",
    "        for iteration in range(36):\n",
    "            if iteration == 0:\n",
    "                block3_configuration.append(Bottleneck(in_channels=512,out_channels=256,stride=2,downsampling=True))\n",
    "            else:\n",
    "                block3_configuration.append(Bottleneck(in_channels=1024,out_channels=256,stride=1,downsampling=False))\n",
    "\n",
    "        self.bottleneck_block3 = nn.Sequential(*block3_configuration)\n",
    "\n",
    "\n",
    "        self.bottleneck_block4 = nn.Sequential(\n",
    "            Bottleneck(in_channels=1024,out_channels=512,stride=2,downsampling=True),\n",
    "            Bottleneck(in_channels=2048,out_channels=512,stride=1,downsampling=False),\n",
    "            Bottleneck(in_channels=2048,out_channels=512,stride=1,downsampling=False)\n",
    "        )\n",
    "\n",
    "        self.avg_pooling_layer = nn.AdaptiveAvgPool2d(output_size=(1,1))\n",
    "        self.output_layer = nn.Linear(2048,classes)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        x = self.conv_layer1(x)\n",
    "        x = self.pooling_layer(x)\n",
    "        x = self.bottleneck_block1(x)\n",
    "        x = self.bottleneck_block2(x)\n",
    "        x = self.bottleneck_block3(x)\n",
    "        x = self.bottleneck_block4(x)\n",
    "        x = self.avg_pooling_layer(x)\n",
    "        x = x.view(x.shape[0],-1)\n",
    "        x = self.output_layer(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 64, 112, 112]           9,408\n",
      "       BatchNorm2d-2         [-1, 64, 112, 112]             128\n",
      "              ReLU-3         [-1, 64, 112, 112]               0\n",
      "         MaxPool2d-4           [-1, 64, 56, 56]               0\n",
      "            Conv2d-5           [-1, 64, 56, 56]           4,096\n",
      "       BatchNorm2d-6           [-1, 64, 56, 56]             128\n",
      "              ReLU-7           [-1, 64, 56, 56]               0\n",
      "            Conv2d-8           [-1, 64, 56, 56]          36,864\n",
      "       BatchNorm2d-9           [-1, 64, 56, 56]             128\n",
      "             ReLU-10           [-1, 64, 56, 56]               0\n",
      "           Conv2d-11          [-1, 256, 56, 56]          16,384\n",
      "      BatchNorm2d-12          [-1, 256, 56, 56]             512\n",
      "           Conv2d-13          [-1, 256, 56, 56]          16,384\n",
      "      BatchNorm2d-14          [-1, 256, 56, 56]             512\n",
      "             ReLU-15          [-1, 256, 56, 56]               0\n",
      "       Bottleneck-16          [-1, 256, 56, 56]               0\n",
      "           Conv2d-17           [-1, 64, 56, 56]          16,384\n",
      "      BatchNorm2d-18           [-1, 64, 56, 56]             128\n",
      "             ReLU-19           [-1, 64, 56, 56]               0\n",
      "           Conv2d-20           [-1, 64, 56, 56]          36,864\n",
      "      BatchNorm2d-21           [-1, 64, 56, 56]             128\n",
      "             ReLU-22           [-1, 64, 56, 56]               0\n",
      "           Conv2d-23          [-1, 256, 56, 56]          16,384\n",
      "      BatchNorm2d-24          [-1, 256, 56, 56]             512\n",
      "             ReLU-25          [-1, 256, 56, 56]               0\n",
      "       Bottleneck-26          [-1, 256, 56, 56]               0\n",
      "           Conv2d-27           [-1, 64, 56, 56]          16,384\n",
      "      BatchNorm2d-28           [-1, 64, 56, 56]             128\n",
      "             ReLU-29           [-1, 64, 56, 56]               0\n",
      "           Conv2d-30           [-1, 64, 56, 56]          36,864\n",
      "      BatchNorm2d-31           [-1, 64, 56, 56]             128\n",
      "             ReLU-32           [-1, 64, 56, 56]               0\n",
      "           Conv2d-33          [-1, 256, 56, 56]          16,384\n",
      "      BatchNorm2d-34          [-1, 256, 56, 56]             512\n",
      "             ReLU-35          [-1, 256, 56, 56]               0\n",
      "       Bottleneck-36          [-1, 256, 56, 56]               0\n",
      "           Conv2d-37          [-1, 128, 56, 56]          32,768\n",
      "      BatchNorm2d-38          [-1, 128, 56, 56]             256\n",
      "             ReLU-39          [-1, 128, 56, 56]               0\n",
      "           Conv2d-40          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-41          [-1, 128, 28, 28]             256\n",
      "             ReLU-42          [-1, 128, 28, 28]               0\n",
      "           Conv2d-43          [-1, 512, 28, 28]          65,536\n",
      "      BatchNorm2d-44          [-1, 512, 28, 28]           1,024\n",
      "           Conv2d-45          [-1, 512, 28, 28]         131,072\n",
      "      BatchNorm2d-46          [-1, 512, 28, 28]           1,024\n",
      "             ReLU-47          [-1, 512, 28, 28]               0\n",
      "       Bottleneck-48          [-1, 512, 28, 28]               0\n",
      "           Conv2d-49          [-1, 128, 28, 28]          65,536\n",
      "      BatchNorm2d-50          [-1, 128, 28, 28]             256\n",
      "             ReLU-51          [-1, 128, 28, 28]               0\n",
      "           Conv2d-52          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-53          [-1, 128, 28, 28]             256\n",
      "             ReLU-54          [-1, 128, 28, 28]               0\n",
      "           Conv2d-55          [-1, 512, 28, 28]          65,536\n",
      "      BatchNorm2d-56          [-1, 512, 28, 28]           1,024\n",
      "             ReLU-57          [-1, 512, 28, 28]               0\n",
      "       Bottleneck-58          [-1, 512, 28, 28]               0\n",
      "           Conv2d-59          [-1, 128, 28, 28]          65,536\n",
      "      BatchNorm2d-60          [-1, 128, 28, 28]             256\n",
      "             ReLU-61          [-1, 128, 28, 28]               0\n",
      "           Conv2d-62          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-63          [-1, 128, 28, 28]             256\n",
      "             ReLU-64          [-1, 128, 28, 28]               0\n",
      "           Conv2d-65          [-1, 512, 28, 28]          65,536\n",
      "      BatchNorm2d-66          [-1, 512, 28, 28]           1,024\n",
      "             ReLU-67          [-1, 512, 28, 28]               0\n",
      "       Bottleneck-68          [-1, 512, 28, 28]               0\n",
      "           Conv2d-69          [-1, 128, 28, 28]          65,536\n",
      "      BatchNorm2d-70          [-1, 128, 28, 28]             256\n",
      "             ReLU-71          [-1, 128, 28, 28]               0\n",
      "           Conv2d-72          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-73          [-1, 128, 28, 28]             256\n",
      "             ReLU-74          [-1, 128, 28, 28]               0\n",
      "           Conv2d-75          [-1, 512, 28, 28]          65,536\n",
      "      BatchNorm2d-76          [-1, 512, 28, 28]           1,024\n",
      "             ReLU-77          [-1, 512, 28, 28]               0\n",
      "       Bottleneck-78          [-1, 512, 28, 28]               0\n",
      "           Conv2d-79          [-1, 128, 28, 28]          65,536\n",
      "      BatchNorm2d-80          [-1, 128, 28, 28]             256\n",
      "             ReLU-81          [-1, 128, 28, 28]               0\n",
      "           Conv2d-82          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-83          [-1, 128, 28, 28]             256\n",
      "             ReLU-84          [-1, 128, 28, 28]               0\n",
      "           Conv2d-85          [-1, 512, 28, 28]          65,536\n",
      "      BatchNorm2d-86          [-1, 512, 28, 28]           1,024\n",
      "             ReLU-87          [-1, 512, 28, 28]               0\n",
      "       Bottleneck-88          [-1, 512, 28, 28]               0\n",
      "           Conv2d-89          [-1, 128, 28, 28]          65,536\n",
      "      BatchNorm2d-90          [-1, 128, 28, 28]             256\n",
      "             ReLU-91          [-1, 128, 28, 28]               0\n",
      "           Conv2d-92          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-93          [-1, 128, 28, 28]             256\n",
      "             ReLU-94          [-1, 128, 28, 28]               0\n",
      "           Conv2d-95          [-1, 512, 28, 28]          65,536\n",
      "      BatchNorm2d-96          [-1, 512, 28, 28]           1,024\n",
      "             ReLU-97          [-1, 512, 28, 28]               0\n",
      "       Bottleneck-98          [-1, 512, 28, 28]               0\n",
      "           Conv2d-99          [-1, 128, 28, 28]          65,536\n",
      "     BatchNorm2d-100          [-1, 128, 28, 28]             256\n",
      "            ReLU-101          [-1, 128, 28, 28]               0\n",
      "          Conv2d-102          [-1, 128, 28, 28]         147,456\n",
      "     BatchNorm2d-103          [-1, 128, 28, 28]             256\n",
      "            ReLU-104          [-1, 128, 28, 28]               0\n",
      "          Conv2d-105          [-1, 512, 28, 28]          65,536\n",
      "     BatchNorm2d-106          [-1, 512, 28, 28]           1,024\n",
      "            ReLU-107          [-1, 512, 28, 28]               0\n",
      "      Bottleneck-108          [-1, 512, 28, 28]               0\n",
      "          Conv2d-109          [-1, 128, 28, 28]          65,536\n",
      "     BatchNorm2d-110          [-1, 128, 28, 28]             256\n",
      "            ReLU-111          [-1, 128, 28, 28]               0\n",
      "          Conv2d-112          [-1, 128, 28, 28]         147,456\n",
      "     BatchNorm2d-113          [-1, 128, 28, 28]             256\n",
      "            ReLU-114          [-1, 128, 28, 28]               0\n",
      "          Conv2d-115          [-1, 512, 28, 28]          65,536\n",
      "     BatchNorm2d-116          [-1, 512, 28, 28]           1,024\n",
      "            ReLU-117          [-1, 512, 28, 28]               0\n",
      "      Bottleneck-118          [-1, 512, 28, 28]               0\n",
      "          Conv2d-119          [-1, 256, 28, 28]         131,072\n",
      "     BatchNorm2d-120          [-1, 256, 28, 28]             512\n",
      "            ReLU-121          [-1, 256, 28, 28]               0\n",
      "          Conv2d-122          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-123          [-1, 256, 14, 14]             512\n",
      "            ReLU-124          [-1, 256, 14, 14]               0\n",
      "          Conv2d-125         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-126         [-1, 1024, 14, 14]           2,048\n",
      "          Conv2d-127         [-1, 1024, 14, 14]         524,288\n",
      "     BatchNorm2d-128         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-129         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-130         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-131          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-132          [-1, 256, 14, 14]             512\n",
      "            ReLU-133          [-1, 256, 14, 14]               0\n",
      "          Conv2d-134          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-135          [-1, 256, 14, 14]             512\n",
      "            ReLU-136          [-1, 256, 14, 14]               0\n",
      "          Conv2d-137         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-138         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-139         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-140         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-141          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-142          [-1, 256, 14, 14]             512\n",
      "            ReLU-143          [-1, 256, 14, 14]               0\n",
      "          Conv2d-144          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-145          [-1, 256, 14, 14]             512\n",
      "            ReLU-146          [-1, 256, 14, 14]               0\n",
      "          Conv2d-147         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-148         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-149         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-150         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-151          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-152          [-1, 256, 14, 14]             512\n",
      "            ReLU-153          [-1, 256, 14, 14]               0\n",
      "          Conv2d-154          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-155          [-1, 256, 14, 14]             512\n",
      "            ReLU-156          [-1, 256, 14, 14]               0\n",
      "          Conv2d-157         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-158         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-159         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-160         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-161          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-162          [-1, 256, 14, 14]             512\n",
      "            ReLU-163          [-1, 256, 14, 14]               0\n",
      "          Conv2d-164          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-165          [-1, 256, 14, 14]             512\n",
      "            ReLU-166          [-1, 256, 14, 14]               0\n",
      "          Conv2d-167         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-168         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-169         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-170         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-171          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-172          [-1, 256, 14, 14]             512\n",
      "            ReLU-173          [-1, 256, 14, 14]               0\n",
      "          Conv2d-174          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-175          [-1, 256, 14, 14]             512\n",
      "            ReLU-176          [-1, 256, 14, 14]               0\n",
      "          Conv2d-177         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-178         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-179         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-180         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-181          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-182          [-1, 256, 14, 14]             512\n",
      "            ReLU-183          [-1, 256, 14, 14]               0\n",
      "          Conv2d-184          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-185          [-1, 256, 14, 14]             512\n",
      "            ReLU-186          [-1, 256, 14, 14]               0\n",
      "          Conv2d-187         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-188         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-189         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-190         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-191          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-192          [-1, 256, 14, 14]             512\n",
      "            ReLU-193          [-1, 256, 14, 14]               0\n",
      "          Conv2d-194          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-195          [-1, 256, 14, 14]             512\n",
      "            ReLU-196          [-1, 256, 14, 14]               0\n",
      "          Conv2d-197         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-198         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-199         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-200         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-201          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-202          [-1, 256, 14, 14]             512\n",
      "            ReLU-203          [-1, 256, 14, 14]               0\n",
      "          Conv2d-204          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-205          [-1, 256, 14, 14]             512\n",
      "            ReLU-206          [-1, 256, 14, 14]               0\n",
      "          Conv2d-207         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-208         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-209         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-210         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-211          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-212          [-1, 256, 14, 14]             512\n",
      "            ReLU-213          [-1, 256, 14, 14]               0\n",
      "          Conv2d-214          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-215          [-1, 256, 14, 14]             512\n",
      "            ReLU-216          [-1, 256, 14, 14]               0\n",
      "          Conv2d-217         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-218         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-219         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-220         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-221          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-222          [-1, 256, 14, 14]             512\n",
      "            ReLU-223          [-1, 256, 14, 14]               0\n",
      "          Conv2d-224          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-225          [-1, 256, 14, 14]             512\n",
      "            ReLU-226          [-1, 256, 14, 14]               0\n",
      "          Conv2d-227         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-228         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-229         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-230         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-231          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-232          [-1, 256, 14, 14]             512\n",
      "            ReLU-233          [-1, 256, 14, 14]               0\n",
      "          Conv2d-234          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-235          [-1, 256, 14, 14]             512\n",
      "            ReLU-236          [-1, 256, 14, 14]               0\n",
      "          Conv2d-237         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-238         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-239         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-240         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-241          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-242          [-1, 256, 14, 14]             512\n",
      "            ReLU-243          [-1, 256, 14, 14]               0\n",
      "          Conv2d-244          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-245          [-1, 256, 14, 14]             512\n",
      "            ReLU-246          [-1, 256, 14, 14]               0\n",
      "          Conv2d-247         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-248         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-249         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-250         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-251          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-252          [-1, 256, 14, 14]             512\n",
      "            ReLU-253          [-1, 256, 14, 14]               0\n",
      "          Conv2d-254          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-255          [-1, 256, 14, 14]             512\n",
      "            ReLU-256          [-1, 256, 14, 14]               0\n",
      "          Conv2d-257         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-258         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-259         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-260         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-261          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-262          [-1, 256, 14, 14]             512\n",
      "            ReLU-263          [-1, 256, 14, 14]               0\n",
      "          Conv2d-264          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-265          [-1, 256, 14, 14]             512\n",
      "            ReLU-266          [-1, 256, 14, 14]               0\n",
      "          Conv2d-267         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-268         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-269         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-270         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-271          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-272          [-1, 256, 14, 14]             512\n",
      "            ReLU-273          [-1, 256, 14, 14]               0\n",
      "          Conv2d-274          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-275          [-1, 256, 14, 14]             512\n",
      "            ReLU-276          [-1, 256, 14, 14]               0\n",
      "          Conv2d-277         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-278         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-279         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-280         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-281          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-282          [-1, 256, 14, 14]             512\n",
      "            ReLU-283          [-1, 256, 14, 14]               0\n",
      "          Conv2d-284          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-285          [-1, 256, 14, 14]             512\n",
      "            ReLU-286          [-1, 256, 14, 14]               0\n",
      "          Conv2d-287         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-288         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-289         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-290         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-291          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-292          [-1, 256, 14, 14]             512\n",
      "            ReLU-293          [-1, 256, 14, 14]               0\n",
      "          Conv2d-294          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-295          [-1, 256, 14, 14]             512\n",
      "            ReLU-296          [-1, 256, 14, 14]               0\n",
      "          Conv2d-297         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-298         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-299         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-300         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-301          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-302          [-1, 256, 14, 14]             512\n",
      "            ReLU-303          [-1, 256, 14, 14]               0\n",
      "          Conv2d-304          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-305          [-1, 256, 14, 14]             512\n",
      "            ReLU-306          [-1, 256, 14, 14]               0\n",
      "          Conv2d-307         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-308         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-309         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-310         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-311          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-312          [-1, 256, 14, 14]             512\n",
      "            ReLU-313          [-1, 256, 14, 14]               0\n",
      "          Conv2d-314          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-315          [-1, 256, 14, 14]             512\n",
      "            ReLU-316          [-1, 256, 14, 14]               0\n",
      "          Conv2d-317         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-318         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-319         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-320         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-321          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-322          [-1, 256, 14, 14]             512\n",
      "            ReLU-323          [-1, 256, 14, 14]               0\n",
      "          Conv2d-324          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-325          [-1, 256, 14, 14]             512\n",
      "            ReLU-326          [-1, 256, 14, 14]               0\n",
      "          Conv2d-327         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-328         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-329         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-330         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-331          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-332          [-1, 256, 14, 14]             512\n",
      "            ReLU-333          [-1, 256, 14, 14]               0\n",
      "          Conv2d-334          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-335          [-1, 256, 14, 14]             512\n",
      "            ReLU-336          [-1, 256, 14, 14]               0\n",
      "          Conv2d-337         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-338         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-339         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-340         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-341          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-342          [-1, 256, 14, 14]             512\n",
      "            ReLU-343          [-1, 256, 14, 14]               0\n",
      "          Conv2d-344          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-345          [-1, 256, 14, 14]             512\n",
      "            ReLU-346          [-1, 256, 14, 14]               0\n",
      "          Conv2d-347         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-348         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-349         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-350         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-351          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-352          [-1, 256, 14, 14]             512\n",
      "            ReLU-353          [-1, 256, 14, 14]               0\n",
      "          Conv2d-354          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-355          [-1, 256, 14, 14]             512\n",
      "            ReLU-356          [-1, 256, 14, 14]               0\n",
      "          Conv2d-357         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-358         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-359         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-360         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-361          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-362          [-1, 256, 14, 14]             512\n",
      "            ReLU-363          [-1, 256, 14, 14]               0\n",
      "          Conv2d-364          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-365          [-1, 256, 14, 14]             512\n",
      "            ReLU-366          [-1, 256, 14, 14]               0\n",
      "          Conv2d-367         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-368         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-369         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-370         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-371          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-372          [-1, 256, 14, 14]             512\n",
      "            ReLU-373          [-1, 256, 14, 14]               0\n",
      "          Conv2d-374          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-375          [-1, 256, 14, 14]             512\n",
      "            ReLU-376          [-1, 256, 14, 14]               0\n",
      "          Conv2d-377         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-378         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-379         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-380         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-381          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-382          [-1, 256, 14, 14]             512\n",
      "            ReLU-383          [-1, 256, 14, 14]               0\n",
      "          Conv2d-384          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-385          [-1, 256, 14, 14]             512\n",
      "            ReLU-386          [-1, 256, 14, 14]               0\n",
      "          Conv2d-387         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-388         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-389         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-390         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-391          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-392          [-1, 256, 14, 14]             512\n",
      "            ReLU-393          [-1, 256, 14, 14]               0\n",
      "          Conv2d-394          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-395          [-1, 256, 14, 14]             512\n",
      "            ReLU-396          [-1, 256, 14, 14]               0\n",
      "          Conv2d-397         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-398         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-399         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-400         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-401          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-402          [-1, 256, 14, 14]             512\n",
      "            ReLU-403          [-1, 256, 14, 14]               0\n",
      "          Conv2d-404          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-405          [-1, 256, 14, 14]             512\n",
      "            ReLU-406          [-1, 256, 14, 14]               0\n",
      "          Conv2d-407         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-408         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-409         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-410         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-411          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-412          [-1, 256, 14, 14]             512\n",
      "            ReLU-413          [-1, 256, 14, 14]               0\n",
      "          Conv2d-414          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-415          [-1, 256, 14, 14]             512\n",
      "            ReLU-416          [-1, 256, 14, 14]               0\n",
      "          Conv2d-417         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-418         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-419         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-420         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-421          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-422          [-1, 256, 14, 14]             512\n",
      "            ReLU-423          [-1, 256, 14, 14]               0\n",
      "          Conv2d-424          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-425          [-1, 256, 14, 14]             512\n",
      "            ReLU-426          [-1, 256, 14, 14]               0\n",
      "          Conv2d-427         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-428         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-429         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-430         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-431          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-432          [-1, 256, 14, 14]             512\n",
      "            ReLU-433          [-1, 256, 14, 14]               0\n",
      "          Conv2d-434          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-435          [-1, 256, 14, 14]             512\n",
      "            ReLU-436          [-1, 256, 14, 14]               0\n",
      "          Conv2d-437         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-438         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-439         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-440         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-441          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-442          [-1, 256, 14, 14]             512\n",
      "            ReLU-443          [-1, 256, 14, 14]               0\n",
      "          Conv2d-444          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-445          [-1, 256, 14, 14]             512\n",
      "            ReLU-446          [-1, 256, 14, 14]               0\n",
      "          Conv2d-447         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-448         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-449         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-450         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-451          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-452          [-1, 256, 14, 14]             512\n",
      "            ReLU-453          [-1, 256, 14, 14]               0\n",
      "          Conv2d-454          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-455          [-1, 256, 14, 14]             512\n",
      "            ReLU-456          [-1, 256, 14, 14]               0\n",
      "          Conv2d-457         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-458         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-459         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-460         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-461          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-462          [-1, 256, 14, 14]             512\n",
      "            ReLU-463          [-1, 256, 14, 14]               0\n",
      "          Conv2d-464          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-465          [-1, 256, 14, 14]             512\n",
      "            ReLU-466          [-1, 256, 14, 14]               0\n",
      "          Conv2d-467         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-468         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-469         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-470         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-471          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-472          [-1, 256, 14, 14]             512\n",
      "            ReLU-473          [-1, 256, 14, 14]               0\n",
      "          Conv2d-474          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-475          [-1, 256, 14, 14]             512\n",
      "            ReLU-476          [-1, 256, 14, 14]               0\n",
      "          Conv2d-477         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-478         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-479         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-480         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-481          [-1, 512, 14, 14]         524,288\n",
      "     BatchNorm2d-482          [-1, 512, 14, 14]           1,024\n",
      "            ReLU-483          [-1, 512, 14, 14]               0\n",
      "          Conv2d-484            [-1, 512, 7, 7]       2,359,296\n",
      "     BatchNorm2d-485            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-486            [-1, 512, 7, 7]               0\n",
      "          Conv2d-487           [-1, 2048, 7, 7]       1,048,576\n",
      "     BatchNorm2d-488           [-1, 2048, 7, 7]           4,096\n",
      "          Conv2d-489           [-1, 2048, 7, 7]       2,097,152\n",
      "     BatchNorm2d-490           [-1, 2048, 7, 7]           4,096\n",
      "            ReLU-491           [-1, 2048, 7, 7]               0\n",
      "      Bottleneck-492           [-1, 2048, 7, 7]               0\n",
      "          Conv2d-493            [-1, 512, 7, 7]       1,048,576\n",
      "     BatchNorm2d-494            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-495            [-1, 512, 7, 7]               0\n",
      "          Conv2d-496            [-1, 512, 7, 7]       2,359,296\n",
      "     BatchNorm2d-497            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-498            [-1, 512, 7, 7]               0\n",
      "          Conv2d-499           [-1, 2048, 7, 7]       1,048,576\n",
      "     BatchNorm2d-500           [-1, 2048, 7, 7]           4,096\n",
      "            ReLU-501           [-1, 2048, 7, 7]               0\n",
      "      Bottleneck-502           [-1, 2048, 7, 7]               0\n",
      "          Conv2d-503            [-1, 512, 7, 7]       1,048,576\n",
      "     BatchNorm2d-504            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-505            [-1, 512, 7, 7]               0\n",
      "          Conv2d-506            [-1, 512, 7, 7]       2,359,296\n",
      "     BatchNorm2d-507            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-508            [-1, 512, 7, 7]               0\n",
      "          Conv2d-509           [-1, 2048, 7, 7]       1,048,576\n",
      "     BatchNorm2d-510           [-1, 2048, 7, 7]           4,096\n",
      "            ReLU-511           [-1, 2048, 7, 7]               0\n",
      "      Bottleneck-512           [-1, 2048, 7, 7]               0\n",
      "AdaptiveAvgPool2d-513           [-1, 2048, 1, 1]               0\n",
      "          Linear-514                 [-1, 1000]       2,049,000\n",
      "================================================================\n",
      "Total params: 60,192,808\n",
      "Trainable params: 60,192,808\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 606.59\n",
      "Params size (MB): 229.62\n",
      "Estimated Total Size (MB): 836.78\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "model = ResNet152(1000)\n",
    "summary(model,(3,224,224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'type_before_parametrizations' from 'torch.nn.utils.parametrize' (c:\\ProgramData\\Anaconda3\\envs\\dl\\lib\\site-packages\\torch\\nn\\utils\\parametrize.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[42], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorchvision\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtransforms\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mtransforms\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorchvision\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdatasets\u001b[39;00m \u001b[39mimport\u001b[39;00m CIFAR100\n\u001b[0;32m      4\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdata\u001b[39;00m \u001b[39mimport\u001b[39;00m DataLoader\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\dl\\lib\\site-packages\\torchvision\\__init__.py:5\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mwarnings\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorchvision\u001b[39;00m \u001b[39mimport\u001b[39;00m datasets, io, models, ops, transforms, utils\n\u001b[0;32m      7\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mextension\u001b[39;00m \u001b[39mimport\u001b[39;00m _HAS_OPS\n\u001b[0;32m      9\u001b[0m \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\dl\\lib\\site-packages\\torchvision\\models\\__init__.py:17\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mswin_transformer\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n\u001b[0;32m     16\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mmaxvit\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n\u001b[1;32m---> 17\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m detection, optical_flow, quantization, segmentation, video\n\u001b[0;32m     18\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_api\u001b[39;00m \u001b[39mimport\u001b[39;00m get_model, get_model_builder, get_model_weights, get_weight, list_models\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\dl\\lib\\site-packages\\torchvision\\models\\quantization\\__init__.py:3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mgooglenet\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n\u001b[0;32m      2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39minception\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n\u001b[1;32m----> 3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mmobilenet\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n\u001b[0;32m      4\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mresnet\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n\u001b[0;32m      5\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mshufflenetv2\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\dl\\lib\\site-packages\\torchvision\\models\\quantization\\mobilenet.py:1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mmobilenetv2\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m  \u001b[39m# noqa: F401, F403\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mmobilenetv3\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m  \u001b[39m# noqa: F401, F403\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mmobilenetv2\u001b[39;00m \u001b[39mimport\u001b[39;00m __all__ \u001b[39mas\u001b[39;00m mv2_all\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\dl\\lib\\site-packages\\torchvision\\models\\quantization\\mobilenetv2.py:5\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtyping\u001b[39;00m \u001b[39mimport\u001b[39;00m Any, Optional, Union\n\u001b[0;32m      4\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorch\u001b[39;00m \u001b[39mimport\u001b[39;00m nn, Tensor\n\u001b[1;32m----> 5\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mao\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mquantization\u001b[39;00m \u001b[39mimport\u001b[39;00m DeQuantStub, QuantStub\n\u001b[0;32m      6\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorchvision\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodels\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmobilenetv2\u001b[39;00m \u001b[39mimport\u001b[39;00m InvertedResidual, MobileNet_V2_Weights, MobileNetV2\n\u001b[0;32m      8\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mops\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmisc\u001b[39;00m \u001b[39mimport\u001b[39;00m Conv2dNormActivation\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\dl\\lib\\site-packages\\torch\\ao\\quantization\\__init__.py:4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# flake8: noqa: F403\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mfake_quantize\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m  \u001b[39m# noqa: F403\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mfuse_modules\u001b[39;00m \u001b[39mimport\u001b[39;00m fuse_modules  \u001b[39m# noqa: F403\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mfuse_modules\u001b[39;00m \u001b[39mimport\u001b[39;00m fuse_modules_qat  \u001b[39m# noqa: F403\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mfuser_method_mappings\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m  \u001b[39m# noqa: F403\u001b[39;00m\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\dl\\lib\\site-packages\\torch\\ao\\quantization\\fuse_modules.py:10\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mao\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mquantization\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mfuser_method_mappings\u001b[39;00m \u001b[39mimport\u001b[39;00m fuse_conv_bn  \u001b[39m# noqa: F401\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mao\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mquantization\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mfuser_method_mappings\u001b[39;00m \u001b[39mimport\u001b[39;00m fuse_conv_bn_relu  \u001b[39m# noqa: F401\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mnn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mparametrize\u001b[39;00m \u001b[39mimport\u001b[39;00m type_before_parametrizations\n\u001b[0;32m     12\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtyping\u001b[39;00m \u001b[39mimport\u001b[39;00m List, Optional\n\u001b[0;32m     14\u001b[0m \u001b[39m# Generalization of getattr\u001b[39;00m\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'type_before_parametrizations' from 'torch.nn.utils.parametrize' (c:\\ProgramData\\Anaconda3\\envs\\dl\\lib\\site-packages\\torch\\nn\\utils\\parametrize.py)"
     ]
    }
   ],
   "source": [
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import CIFAR100\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEVICE: cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print('DEVICE:',device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                           transforms.Normalize((0.485,0.456,0.406),(0.229,0.224,0.225))])\n",
    "\n",
    "train_set = CIFAR100(root=r'C:\\Users\\Administrator\\Desktop\\Dataset',\n",
    "                           transform=transform,\n",
    "                           train=True,\n",
    "                           download=True\n",
    "                           )\n",
    "test_set = CIFAR100(root=r'C:\\Users\\Administrator\\Desktop\\Dataset',\n",
    "                           transform=transform,\n",
    "                           train=False,\n",
    "                           download=True\n",
    "                           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(dataset=train_set,\n",
    "                          batch_size=32,\n",
    "                          shuffle=True,\n",
    "                          drop_last=True)\n",
    "\n",
    "test_loader = DataLoader(dataset=test_set,\n",
    "                         drop_last=True,\n",
    "                         shuffle=True,\n",
    "                         batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ResNet18(100).to(device)\n",
    "\n",
    "num_epochs = 30\n",
    "batch_size = 128\n",
    "num_train_batchs = len(train_loader)\n",
    "num_test_batchs = len(test_loader)\n",
    "\n",
    "loss_func = nn.CrossEntropyLoss().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "544253c7c9b54012bd8a85429d53e9cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f139241ccb1542afb80041fe32f4718b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1562 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 20\u001b[0m\n\u001b[0;32m     17\u001b[0m     epoch_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m batch_loss\u001b[39m/\u001b[39mnum_train_batchs\n\u001b[0;32m     18\u001b[0m     epoch_correct_count \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m (outputs\u001b[39m.\u001b[39margmax(dim\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\u001b[39m==\u001b[39mlabels)\u001b[39m.\u001b[39msum()\u001b[39m.\u001b[39mitem()\n\u001b[1;32m---> 20\u001b[0m     batch_loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[0;32m     21\u001b[0m     optimizer\u001b[39m.\u001b[39mstep()\n\u001b[0;32m     22\u001b[0m epoch_accuracy \u001b[39m=\u001b[39m epoch_correct_count\u001b[39m/\u001b[39m\u001b[39mlen\u001b[39m(train_set)\u001b[39m*\u001b[39m\u001b[39m100\u001b[39m\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\dl\\lib\\site-packages\\torch\\_tensor.py:488\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    478\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[0;32m    479\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    480\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[0;32m    481\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    486\u001b[0m         inputs\u001b[39m=\u001b[39minputs,\n\u001b[0;32m    487\u001b[0m     )\n\u001b[1;32m--> 488\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\n\u001b[0;32m    489\u001b[0m     \u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs\n\u001b[0;32m    490\u001b[0m )\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\dl\\lib\\site-packages\\torch\\autograd\\__init__.py:197\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    192\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[0;32m    194\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[0;32m    195\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    196\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 197\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    198\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[0;32m    199\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#학습 진행\n",
    "for epoch in tqdm(range(num_epochs)):\n",
    "    model.train()\n",
    "    \n",
    "    epoch_loss = 0.0\n",
    "    epoch_correct_count = 0\n",
    "\n",
    "    for data in tqdm(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        imgs,labels = data\n",
    "        imgs,labels = imgs.to(device), labels.to(device)\n",
    "\n",
    "        outputs = model(imgs)\n",
    "        batch_loss = loss_func(outputs,labels)\n",
    "\n",
    "        epoch_loss += batch_loss/num_train_batchs\n",
    "        epoch_correct_count += (outputs.argmax(dim=-1)==labels).sum().item()\n",
    "        \n",
    "        batch_loss.backward()\n",
    "        optimizer.step()\n",
    "    epoch_accuracy = epoch_correct_count/len(train_set)*100\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        val_loss = 0.0\n",
    "        val_correct_count = 0\n",
    "\n",
    "        for data in test_loader:\n",
    "            val_imgs, val_labels = data\n",
    "            val_imgs, val_labels = val_imgs.to(device), val_labels.to(device)\n",
    "\n",
    "            val_outputs = model(val_imgs)\n",
    "            val_batch_loss = loss_func(val_outputs,val_labels)\n",
    "            val_loss += val_batch_loss/num_test_batchs\n",
    "\n",
    "            val_correct_count += (val_outputs.argmax(dim=-1)==val_labels).sum().item()\n",
    "        val_accuracy = val_correct_count/len(test_set)*100\n",
    "\n",
    "    print(f'[EPOCH {epoch+1:2}/{num_epochs:2}] [TRAIN LOSS: {epoch_loss:5f}] [TRAIN ACCURACY: {epoch_accuracy:2f}%] [VAL LOSS: {val_loss:5f}] [VAL ACCURACY: {val_accuracy:2f}%]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c9ccd8639d7ac6d8ae46f08631d02de0d1c9f4a08850208985333be71082afd9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
