{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# LeNet-5\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 라이브러리 불러오기\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torchsummary import summary\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 디바이스 설정\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print('DEVICE:',device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#이미지 다운로드, 전처리\n",
    "trans = transforms.Compose([transforms.ToTensor(),\n",
    "                           transforms.Resize(32)])\n",
    "\n",
    "train_set = datasets.MNIST(root=r'C:\\Users\\Administrator\\Desktop\\Dataset',\n",
    "                           transform=trans,\n",
    "                           train=True,\n",
    "                           download=True\n",
    "                           )\n",
    "test_set = datasets.MNIST(root=r'C:\\Users\\Administrator\\Desktop\\Dataset',\n",
    "                           transform=trans,\n",
    "                           train=False,\n",
    "                           download=True\n",
    "                           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(dataset=train_set,\n",
    "                          batch_size=64,\n",
    "                          shuffle=True,\n",
    "                          drop_last=True)\n",
    "\n",
    "test_loader = DataLoader(dataset=test_set,\n",
    "                          batch_size=len(test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#이미지 시각화\n",
    "fig = plt.figure(figsize=(8,8))\n",
    "\n",
    "columns = 5\n",
    "rows = 5\n",
    "\n",
    "for i in range(1,columns*rows+1):\n",
    "    img_xy = np.random.randint(len(train_set))\n",
    "    img = train_set[img_xy][0][0]\n",
    "    fig.add_subplot(rows,columns,i)\n",
    "    plt.title(train_set[img_xy][1])\n",
    "    plt.axis('off')\n",
    "    plt.imshow(img,cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#모델 정의\n",
    "class LeNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LeNet,self).__init__()\n",
    "\n",
    "        self.conv_layer1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1,out_channels=6,kernel_size=5,stride=1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "        self.sub_sampling_layer1 = nn.MaxPool2d(kernel_size=2,stride=2)\n",
    "\n",
    "        self.conv_layer2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=6,out_channels=16,kernel_size=5,stride=1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "        self.sub_sampling_layer2 = nn.MaxPool2d(kernel_size=2,stride=2)\n",
    "\n",
    "        self.flatten = nn.Flatten()\n",
    "\n",
    "        self.fc_layer1 = nn.Sequential(\n",
    "            nn.Linear(5*5*16,400),\n",
    "            nn.Sigmoid()\n",
    "            )\n",
    "        \n",
    "        self.fc_layer2 = nn.Sequential(\n",
    "            nn.Linear(400,120),\n",
    "            nn.Sigmoid()\n",
    "            )\n",
    "        \n",
    "        self.fc_layer3 = nn.Sequential(\n",
    "            nn.Linear(120,84),\n",
    "            nn.Sigmoid()\n",
    "            )\n",
    "        \n",
    "        self.output_layer = nn.Linear(84,10)\n",
    "            \n",
    "\n",
    "    def forward(self,x):\n",
    "        x = self.conv_layer1(x)\n",
    "        x = self.sub_sampling_layer1(x)\n",
    "        x = self.conv_layer2(x)\n",
    "        x = self.sub_sampling_layer2(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc_layer1(x)\n",
    "        x = self.fc_layer2(x)\n",
    "        x = self.fc_layer3(x)\n",
    "        x = self.output_layer(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#하이퍼 파라미터 설정\n",
    "model = LeNet().to(device)\n",
    "\n",
    "num_epochs = 10\n",
    "batch_size = 64\n",
    "num_batchs = len(train_loader)\n",
    "\n",
    "loss_func = nn.CrossEntropyLoss().to(device)\n",
    "optimizer = optim.Adam(model.parameters(),lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#학습 진행\n",
    "for epoch in tqdm(range(num_epochs)):\n",
    "    model.train()\n",
    "    \n",
    "    epoch_loss = 0.0\n",
    "    epoch_correct_count = 0\n",
    "\n",
    "    for data in tqdm(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        imgs,labels = data\n",
    "        imgs,labels = imgs.to(device), labels.to(device)\n",
    "\n",
    "        outputs = model(imgs)\n",
    "        batch_loss = loss_func(outputs,labels)\n",
    "\n",
    "        epoch_loss += batch_loss/num_batchs\n",
    "        epoch_correct_count += (outputs.argmax(dim=-1)==labels).sum().item()\n",
    "        \n",
    "        batch_loss.backward()\n",
    "        optimizer.step()\n",
    "    epoch_accuracy = epoch_correct_count/len(train_set)*100\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for data in test_loader:\n",
    "            val_imgs, val_labels = data\n",
    "            val_imgs, val_labels = val_imgs.to(device), val_labels.to(device)\n",
    "\n",
    "            val_outputs = model(val_imgs)\n",
    "            val_loss = loss_func(val_outputs,val_labels)\n",
    "            val_correct_count = (val_outputs.argmax(dim=-1)==val_labels).sum().item()\n",
    "            val_accuracy = val_correct_count/len(test_set)*100\n",
    "\n",
    "    print(f'[EPOCH {epoch+1:2}/{num_epochs:2}] [TRAIN LOSS: {epoch_loss:5f}] [TRAIN ACCURACY: {epoch_accuracy:2f}%] [VAL LOSS: {val_loss:5f}] [VAL ACCURACY: {val_accuracy:2f}%]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c9ccd8639d7ac6d8ae46f08631d02de0d1c9f4a08850208985333be71082afd9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
